{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor-Compressed PINN for Solving Burgers Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backend/Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy.stats import qmc\n",
    "import tensorlearn as tl\n",
    "import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##nn basics\n",
    "\n",
    "def read_network(network_path):\n",
    "\n",
    "    saved_model = tf.keras.models.load_model(network_path)\n",
    "\n",
    "    return saved_model\n",
    "\n",
    "\n",
    "\n",
    "def layer_param(nn_model, layer_name):\n",
    "\n",
    "    return nn_model.get_layer(layer_name).weights\n",
    "\n",
    "\n",
    "\n",
    "def get_dense_layer_weights(param):\n",
    "    return param[0].numpy()\n",
    "\n",
    "def get_dense_layer_bias(param):\n",
    "    return param[1].numpy()\n",
    "\n",
    "def set_dense_layer_param_list(weights,bias):\n",
    "    return [weights,bias]\n",
    "\n",
    "\n",
    "    \n",
    "def freez_layer(nn_model,index, param_layer):\n",
    "    nn_model.layers[index].set_weights(param_layer)\n",
    "    nn_model.layers[index].trainable=False\n",
    "    return nn_model\n",
    "\n",
    "\n",
    "def net_retrain(nn_model, ds_train, ds_test, epochs, output_path):\n",
    "\n",
    "\n",
    "    checkpoint_path=output_path\n",
    "    cp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 save_weights_only=False,\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "    nn_model.fit(\n",
    "                ds_train,\n",
    "                epochs=epochs,\n",
    "                validation_data=ds_test,\n",
    "                callbacks=[cp_callback]\n",
    "            )                \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    nn_model.save(output_path)\n",
    "    return nn_model\n",
    "\n",
    "\n",
    "def get_layer_index_by_name(model, layer_name):\n",
    "    for index, layer in enumerate(model.layers):\n",
    "        if layer.name == layer_name:\n",
    "            return index\n",
    "        \n",
    "\n",
    "def inference(nn_model, ds_test):\n",
    "    return nn_model.evaluate(ds_test)\n",
    "\n",
    "\n",
    "\n",
    "def mnist_data_load(batch_size=128):\n",
    "        tfds.disable_progress_bar()\n",
    "        #tf.enable_v2_behavior()\n",
    "        \n",
    "        (ds_train, ds_test), ds_info = tfds.load(\n",
    "            'fashion_mnist',\n",
    "            split=['train', 'test'],\n",
    "            shuffle_files=True,\n",
    "            as_supervised=True,\n",
    "            with_info=True,\n",
    "        )\n",
    "        \n",
    "        def normalize_img(image, label):\n",
    "          \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "          return tf.cast(image, tf.float32) / 255., label\n",
    "        \n",
    "        ds_train = ds_train.map(\n",
    "            normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        ds_train = ds_train.cache()\n",
    "        ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "        ds_train = ds_train.batch(batch_size)\n",
    "        ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "        ds_test = ds_test.map(\n",
    "            normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        ds_test = ds_test.batch(batch_size)\n",
    "        ds_test = ds_test.cache()\n",
    "        ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        return ds_train, ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 50)                150       \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,701\n",
      "Trainable params: 25,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "#tcPINN = tf.keras.models.load_model(\"b_14x50.h5\")\n",
    "model_name = 'b_10x50.h5'\n",
    "tcPINN = tf.keras.models.load_model(model_name)\n",
    "tcPINN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available.\n"
     ]
    }
   ],
   "source": [
    "#FIX THIS - GPU setup\n",
    "#pip install tensorflow-gpu\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) == 0:\n",
    "    print(\"No GPU available.\")\n",
    "else:\n",
    "    print(\"GPU(s) available:\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decomposing and recomposing a layer of weights\n",
    "def decomp_recomp(weights, epsilon, shape, layer, save_layer):\n",
    "\n",
    "    og_shape = np.array(weights.shape)\n",
    "    #print(type(og_shape))\n",
    "    np_weights = np.array(weights)\n",
    "    #print(np_weights.shape)\n",
    "    #print(type(np_weights))\n",
    "\n",
    "    weights_3d = np.reshape(np_weights, shape).astype(np.float64) #shape search???\n",
    "    #20x20 = 10 8 5\n",
    "    #40x40 = 16 10 10\n",
    "    #60x60 = 16 15 15\n",
    "\n",
    "    #print(type(weights_3d))\n",
    "\n",
    "    #decompose/recompose\n",
    "    tt_weights = tl.auto_rank_tt(weights_3d, epsilon) #error of 0.5 - 1, tweak w shape search?\n",
    "    recomp_weights = tl.tt_to_tensor(tt_weights)\n",
    "\n",
    "    #data saving\n",
    "    compression_ratio = tl.tt_compression_ratio(tt_weights)\n",
    "    data_saving = 1 - (1/compression_ratio)\n",
    "    print(\"data_saving (%)\", data_saving*100)\n",
    "\n",
    "    #save compressed layer\n",
    "    if(save_layer):\n",
    "        tt_weights_npy = np.array(tt_weights, dtype=object)\n",
    "        np.save(f'{layer}.npy', tt_weights_npy)\n",
    "\n",
    "    return np.reshape(recomp_weights, og_shape) #og shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate loss\n",
    "\n",
    "### generating data\n",
    "\n",
    "# number of boundary and initial data points\n",
    "# value `Nd` in the reference paper:\n",
    "# Nd = number_of_ic_points + number_of_bc1_points + number_of_bc1_points \n",
    "number_of_ic_points = 50\n",
    "number_of_bc1_points = 25\n",
    "number_of_bc2_points = 25\n",
    "\n",
    "# Latin Hypercube Sampling (LHS) engine ; to sample random points in domain,\n",
    "# boundary and initial boundary\n",
    "engine = qmc.LatinHypercube(d=1)\n",
    "\n",
    "# temporal data points\n",
    "t_d = engine.random(n=number_of_bc1_points + number_of_bc2_points)\n",
    "temp = np.zeros([number_of_ic_points, 1]) # for IC ; t = 0\n",
    "t_d = np.append(temp, t_d, axis=0)\n",
    "# spatial data points\n",
    "x_d = engine.random(n=number_of_ic_points)\n",
    "x_d = 2 * (x_d - 0.5)\n",
    "temp1 = -1 * np.ones([number_of_bc1_points, 1]) # for BC1 ; x = -1\n",
    "temp2 = +1 * np.ones([number_of_bc2_points, 1]) # for BC2 ; x = +1\n",
    "x_d = np.append(x_d, temp1, axis=0)\n",
    "x_d = np.append(x_d, temp2, axis=0)\n",
    "\n",
    "# output values for data points (boundary and initial)\n",
    "y_d = np.zeros(x_d.shape)\n",
    "\n",
    "# for initial condition: IC = -sin(pi*x)\n",
    "y_d[ : number_of_ic_points] = -np.sin(np.pi * x_d[:number_of_ic_points])\n",
    "\n",
    "# all boundary conditions are set to zero\n",
    "y_d[number_of_ic_points : number_of_bc1_points + number_of_ic_points] = 0\n",
    "y_d[number_of_bc1_points + number_of_ic_points : number_of_bc1_points + number_of_ic_points + number_of_bc2_points] = 0\n",
    "\n",
    "# number of collocation points\n",
    "Nc = 10000\n",
    "\n",
    "# LHS for collocation points\n",
    "engine = qmc.LatinHypercube(d=2)\n",
    "data = engine.random(n=Nc)\n",
    "# set x values between -1. and +1.\n",
    "data[:, 1] = 2*(data[:, 1]-0.5)\n",
    "\n",
    "# change names\n",
    "t_c = np.expand_dims(data[:, 0], axis=1)\n",
    "x_c = np.expand_dims(data[:, 1], axis=1)\n",
    "\n",
    "# MSE loss function\n",
    "# IMPORTANT: this loss function is used for data points\n",
    "@tf.function\n",
    "def mse(y, y_):\n",
    "    return tf.reduce_mean(tf.square(y-y_))\n",
    "\n",
    "def calc_loss(model):\n",
    "\n",
    "    # u(t, x) just makes working with model easier and the whole code looks more\n",
    "    # like its mathematical backend\n",
    "    @tf.function\n",
    "    def u(t, x, model):\n",
    "        # model input shape is (2,) and `u` recieves 2 arguments with shape (1,)\n",
    "        # to be able to feed those 2 args (t, x) to the model, a shape (2,) matrix\n",
    "        # is build by simply concatenation of (t, x)\n",
    "        u = model(tf.concat([t, x], axis=1)) # note the axis ; `column`\n",
    "        return u\n",
    "    \n",
    "    # the physics informed loss function\n",
    "    # IMPORTANT: this loss function is used for collocation points\n",
    "    @tf.function\n",
    "    def f(t, x, model):\n",
    "        u0 = u(t, x, model)\n",
    "        u_t = tf.gradients(u0, t)[0]\n",
    "        u_x = tf.gradients(u0, x)[0]\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        F = u_t + u0*u_x - (0.01/np.pi)*u_xx\n",
    "        return tf.reduce_mean(tf.square(F))\n",
    "    \n",
    "    # model output/prediction\n",
    "    y_ = u(t_d, x_d, model)\n",
    "    # physics-informed loss for collocation points\n",
    "    L1 = f(t_c, x_c, model)\n",
    "    # MSE loss for data points\n",
    "    L2 = mse(y_d, y_)\n",
    "    loss = L1 + L2\n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain model\n",
    "\n",
    "def retrain(model, epochs):\n",
    "\n",
    "    #loss funciton definitions\n",
    "    # u(t, x) just makes working with model easier and the whole code looks more\n",
    "    # like its mathematical backend\n",
    "    @tf.function\n",
    "    def u(t, x, model):\n",
    "        # model input shape is (2,) and `u` recieves 2 arguments with shape (1,)\n",
    "        # to be able to feed those 2 args (t, x) to the model, a shape (2,) matrix\n",
    "        # is build by simply concatenation of (t, x)\n",
    "        u = model(tf.concat([t, x], axis=1)) # note the axis ; `column`\n",
    "        return u\n",
    "    \n",
    "    # the physics informed loss function\n",
    "    # IMPORTANT: this loss function is used for collocation points\n",
    "    @tf.function\n",
    "    def f(t, x, model):\n",
    "        u0 = u(t, x, model)\n",
    "        u_t = tf.gradients(u0, t)[0]\n",
    "        u_x = tf.gradients(u0, x)[0]\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        F = u_t + u0*u_x - (0.01/np.pi)*u_xx\n",
    "        return tf.reduce_mean(tf.square(F))\n",
    "\n",
    "    loss_list = []\n",
    "\n",
    "    # L-BFGS optimizer was used in the reference paper\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    start = time.time()\n",
    "\n",
    "    # training loop\n",
    "    # IMPORTANT: a while-based training loop is more beneficial\n",
    "    # updates the model while loss > 0.006\n",
    "    for epoch in range(epochs + 1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # model output/prediction\n",
    "            y_ = u(t_d, x_d, model)\n",
    "            # physics-informed loss for collocation points\n",
    "            L1 = f(t_c, x_c, model)\n",
    "            # MSE loss for data points\n",
    "            L2 = mse(y_d, y_)\n",
    "            loss = L1 + L2\n",
    "        # compute gradients\n",
    "        g = tape.gradient(loss, model.trainable_weights)\n",
    "        loss_list.append(loss)\n",
    "        # log every 10 epochs\n",
    "        if (not epoch%50) or (epoch == epochs):\n",
    "            print(f\"{epoch:4} {loss.numpy()}\")\n",
    "        # apply gradients\n",
    "        opt.apply_gradients(zip(g, model.trainable_weights))\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"{end - start:.10} (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#reset tcPINN\n",
    "og_model = tf.keras.models.load_model(\"burgers.h5\") #loss = 0.00591\n",
    "og_weights = og_model.get_weights()\n",
    "tcPINN.set_weights(og_weights)\n",
    "for i in range(11):\n",
    "    tcPINN.layers[i].set_trainable = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual TT Decomp and Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "0.0006366909955450453\n",
      "----------------- 1 -----------------\n",
      "data_saving (%) 90.44444444444444\n",
      "   0 1.0963152636606994\n",
      "  50 0.10531905384203098\n",
      " 100 0.08503314799533111\n",
      " 150 0.06542739105200296\n",
      " 200 0.058611546209179785\n",
      " 250 0.05519542842959165\n",
      " 300 0.05256535884986857\n",
      " 350 0.04941559975157655\n",
      " 400 0.04501525788884743\n",
      " 450 0.038074282861899775\n",
      " 500 0.023970584036924\n",
      " 550 0.03244921187475032\n",
      " 600 0.014573194624540502\n",
      " 650 0.00869245805753686\n",
      " 700 0.04389853526486509\n",
      " 750 0.004946856407866088\n",
      " 800 0.0033078389079995805\n",
      " 850 0.0026387887543837664\n",
      " 900 0.0021917677154560835\n",
      " 950 0.0018697226012918196\n",
      "1000 0.0016255247938982737\n",
      "1050 0.006132037276410684\n",
      "1100 0.0013571752148198797\n",
      "1150 0.0013950287567956873\n",
      "1200 0.0015400470872849157\n",
      "1250 0.004131961764590149\n",
      "1300 0.0011152607910437382\n",
      "1350 0.0019088377640982027\n",
      "1400 0.0015356354075201236\n",
      "1450 0.001322129776671813\n",
      "1500 0.0007546567774496906\n",
      "1550 0.0008346928769482655\n",
      "1600 0.0007160113797080386\n",
      "1650 0.0006696109437978608\n",
      "1700 0.001985688794466518\n",
      "1750 0.0011811746904121176\n",
      "1800 0.0012225575041090342\n",
      "1850 0.000571359529342763\n",
      "1900 0.0005072610430211304\n",
      "1950 0.0004461282283205082\n",
      "2000 0.000797264961769453\n",
      "1961.627095 (s)\n",
      "(30, 30)\n",
      "----------------- 2 -----------------\n",
      "data_saving (%) 90.44444444444444\n",
      "   0 1.5033998763892766\n",
      "  50 0.22604208411510415\n",
      " 100 0.17611929779603072\n",
      " 150 0.11544317847497976\n",
      " 200 0.09425712321504301\n",
      " 250 0.08319496603408139\n",
      " 300 0.07806519757206357\n",
      " 350 0.07273383897159652\n",
      " 400 0.06581500681757582\n",
      " 450 0.060300869934027876\n",
      " 500 0.05653288536264173\n",
      " 550 0.053465351863124094\n",
      " 600 0.05040711147362596\n",
      " 650 0.04574832862738556\n",
      " 700 0.039267291585118005\n",
      " 750 0.04834448163134468\n",
      " 800 0.03320219566435048\n",
      " 850 0.019718542903106602\n",
      " 900 0.023360160265189292\n",
      " 950 0.014166527277605773\n",
      "1000 0.007738366649623283\n",
      "1050 0.008421754186567857\n",
      "1100 0.005317480828292855\n",
      "1150 0.0035552441405507324\n",
      "1200 0.0027687493136862337\n",
      "1250 0.002462385292382596\n",
      "1300 0.015844497934814503\n",
      "1350 0.005507834364182241\n",
      "1400 0.0038342552833533737\n",
      "1450 0.0029378627484035\n",
      "1500 0.0025887086336424192\n",
      "1550 0.0023206397604817334\n",
      "1600 0.0017877948206432561\n",
      "1650 0.001599262259651709\n",
      "1700 0.001458656923678378\n",
      "1750 0.0013368331175780046\n",
      "1800 0.0012059424662599692\n",
      "1850 0.0011217262026004381\n",
      "1900 0.0011194342423800048\n",
      "1950 0.0008038550425379952\n",
      "2000 0.0007182647223909795\n",
      "2051.137154 (s)\n",
      "(30, 30)\n",
      "----------------- 3 -----------------\n",
      "data_saving (%) 90.44444444444444\n",
      "   0 0.7235163853224781\n",
      "  50 0.0696286130789641\n",
      " 100 0.04312478596836085\n",
      " 150 0.015489766705406577\n",
      " 200 0.007654191481006243\n",
      " 250 0.013688935628528522\n",
      " 300 0.004019446277064054\n",
      " 350 0.003120800832365294\n",
      " 400 0.0026836983915089164\n",
      " 450 0.0024190191460404394\n",
      " 500 0.002305855019767831\n",
      " 550 0.0017404943528350038\n",
      " 600 0.002146782494564012\n",
      " 650 0.0016655650074500522\n",
      " 700 0.009684588063993435\n",
      " 750 0.0026939339622017943\n",
      " 800 0.0010720486254779643\n",
      " 850 0.0009555345075049468\n",
      " 900 0.0008901335621811108\n",
      " 950 0.0008366279864960382\n",
      "1000 0.000790755847770322\n",
      "1050 0.000750388360266658\n",
      "1100 0.006113356209560801\n",
      "1150 0.0010660832501248147\n",
      "1200 0.0007391382189216492\n",
      "1250 0.000687802387705863\n",
      "1300 0.000656975842369517\n",
      "1350 0.0006308982167584083\n",
      "1400 0.0006074078505658148\n",
      "1450 0.0005857742420103719\n",
      "1500 0.0005655925360318849\n",
      "1550 0.0005465947498829475\n",
      "1600 0.0005285900243064616\n",
      "1650 0.0005114369064195354\n",
      "1700 0.000495027601804979\n",
      "1750 0.00047927812049345156\n",
      "1800 0.00280045399008493\n",
      "1850 0.006712853898385602\n",
      "1900 0.0008831513893174461\n",
      "1950 0.0005143020772877499\n",
      "2000 0.00046564577615219405\n",
      "1976.387142 (s)\n",
      "(30, 30)\n",
      "----------------- 4 -----------------\n",
      "data_saving (%) 90.44444444444444\n",
      "   0 1.4744271768193133\n",
      "  50 0.20226872389369419\n",
      " 100 0.12517331464521655\n",
      " 150 0.10614397577108226\n",
      " 200 0.10012912243533456\n",
      " 250 0.09561797141796508\n",
      " 300 0.088735029508307\n",
      " 350 0.06773304969273193\n",
      " 400 0.05617919313219594\n",
      " 450 0.0529890797614324\n",
      " 500 0.050203450128898375\n",
      " 550 0.04482410210692393\n",
      " 600 0.034508009485461254\n",
      " 650 0.02549104268610293\n",
      " 700 0.01661533920797709\n",
      " 750 0.01404168036686168\n",
      " 800 0.009732168847514289\n",
      " 850 0.009152035941968817\n",
      " 900 0.006416290126407544\n",
      " 950 0.004220212612526428\n",
      "1000 0.002945130894210079\n",
      "1050 0.002467454156795161\n",
      "1100 0.002121547595904814\n",
      "1150 0.0018407591856290835\n",
      "1200 0.0016088810530068755\n",
      "1250 0.0014176787832346678\n",
      "1300 0.0012603609742007434\n",
      "1350 0.0011305828972128932\n",
      "1400 0.0010227974467120462\n",
      "1450 0.01916814408726435\n",
      "1500 0.0014391675108000159\n",
      "1550 0.0010584890867656213\n",
      "1600 0.0009528758673131354\n",
      "1650 0.0008886573979684036\n",
      "1700 0.0008380835545481588\n",
      "1750 0.0007944178101068383\n",
      "1800 0.0007553581233182341\n",
      "1850 0.0007198017545950405\n",
      "1900 0.001459696733818194\n",
      "1950 0.0006628222344232109\n",
      "2000 0.0006623884137426231\n",
      "1954.913151 (s)\n",
      "(30, 30)\n",
      "----------------- 5 -----------------\n",
      "data_saving (%) 90.44444444444444\n",
      "   0 5.935899467431835\n",
      "  50 0.16568692168374274\n",
      " 100 0.1301111334863012\n",
      " 150 0.11772337721446291\n",
      " 200 0.10839884612873969\n",
      " 250 0.09963317533150173\n",
      " 300 0.08966598505578151\n",
      " 350 0.07881249259696207\n",
      " 400 0.07067063681130344\n",
      " 450 0.06577116499951521\n",
      " 500 0.06248340244782441\n",
      " 550 0.05995206816170123\n",
      " 600 0.05788725319870114\n",
      " 650 0.05611308420446526\n",
      " 700 0.05450115156304683\n",
      " 750 0.05295327993318136\n",
      " 800 0.05138094365313564\n",
      " 850 0.04968972563375606\n",
      " 900 0.047775988226319815\n",
      " 950 0.04554163854048517\n",
      "1000 0.04294121308107625\n",
      "1050 0.04004109252015914\n",
      "1100 0.03684900253128569\n",
      "1150 0.033138469342754176\n",
      "1200 0.028791234918634764\n",
      "1250 0.024101533296072182\n",
      "1300 0.019750417810924185\n",
      "1350 0.016202786871598557\n",
      "1400 0.013300590918365971\n",
      "1450 0.010917423009859949\n",
      "1500 0.009161168631485549\n",
      "1550 0.007586113178706992\n",
      "1600 0.007090702472704973\n",
      "1650 0.006296676869999494\n",
      "1700 0.005745358344049201\n",
      "1750 0.005240608250356295\n",
      "1800 0.004569069094357461\n",
      "1850 0.005169679518328815\n",
      "1900 0.0038520524027154507\n",
      "1950 0.004012165421260512\n",
      "2000 0.0034407950942539896\n",
      "1961.794466 (s)\n",
      "(30, 30)\n",
      "----------------- 6 -----------------\n",
      "data_saving (%) 90.44444444444444\n",
      "   0 2.03338290951447\n",
      "  50 0.09010318091553211\n",
      " 100 0.061635935170581545\n",
      " 150 0.04844765986064301\n",
      " 200 0.039207902603807035\n",
      " 250 0.03255711407226419\n",
      " 300 0.02693769045138961\n",
      " 350 0.021873061617099298\n",
      " 400 0.018411048936159854\n",
      " 450 0.015842534314210427\n",
      " 500 0.01462765235356675\n",
      " 550 0.012761268833764846\n",
      " 600 0.011474971730348445\n",
      " 650 0.010347597837223148\n",
      " 700 0.00931518613031004\n",
      " 750 0.008400399163807033\n",
      " 800 0.007618528051537064\n",
      " 850 0.007116528924287019\n",
      " 900 0.006404179420607616\n",
      " 950 0.005879398598054229\n",
      "1000 0.0054143810796451215\n",
      "1050 0.5054898139554346\n",
      "1100 0.13727773491148515\n",
      "1150 0.06201604873523408\n",
      "1200 0.033716834421810706\n",
      "1250 0.020034482344648614\n",
      "1300 0.013326625114214858\n",
      "1350 0.009153615586823172\n",
      "1400 0.006071829640937118\n",
      "1450 0.00467596436777872\n",
      "1500 0.0038338606349517792\n",
      "1550 0.0034099362876138612\n",
      "1600 0.003127814254301918\n",
      "1650 0.00287383098957895\n",
      "1700 0.0026978977181995292\n",
      "1750 0.0025537762973031363\n",
      "1800 0.002399107972154104\n",
      "1850 0.00228472781479475\n",
      "1900 0.0021889143506625955\n",
      "1950 0.002102093790775871\n",
      "2000 0.002021492131799421\n",
      "1980.502932 (s)\n",
      "(30, 30)\n",
      "----------------- 7 -----------------\n",
      "data_saving (%) 90.44444444444444\n",
      "   0 3.007568312125452\n",
      "  50 0.0796622806324855\n",
      " 100 0.06320663839316648\n",
      " 150 0.05288058057113981\n",
      " 200 0.043709176895078604\n",
      " 250 0.03711735713276981\n",
      " 300 0.03191668874290889\n",
      " 350 0.027393952162242587\n",
      " 400 0.02319406235248374\n",
      " 450 0.01959153306045905\n",
      " 500 0.016571896085646097\n",
      " 550 0.014013697417952919\n",
      " 600 0.011995829693362374\n",
      " 650 0.010335783842598003\n",
      " 700 0.009010452274356684\n",
      " 750 0.007956781659124865\n",
      " 800 0.007092761053464664\n",
      " 850 0.006245100603890328\n",
      " 900 0.005639723154355287\n",
      " 950 0.005142933399642636\n",
      "1000 0.004712841339754725\n",
      "1050 0.004332261524176512\n",
      "1100 0.003816370559334348\n",
      "1150 0.0034868201103936125\n",
      "1200 0.003245298952204549\n",
      "1250 0.003040724718767781\n",
      "1300 0.002863481129091275\n",
      "1350 0.0027070775163517405\n",
      "1400 0.002566411075385449\n",
      "1450 0.0024375760730998256\n",
      "1500 0.0023177012700616477\n",
      "1550 0.002204754128860629\n",
      "1600 0.0020973345132689605\n",
      "1650 0.0024271147162142756\n",
      "1700 0.0019229882105749486\n",
      "1750 0.0018315231192951764\n",
      "1800 0.0017380405609964224\n",
      "1850 0.0019044034860520214\n",
      "1900 0.0015613553739238521\n",
      "1950 0.0015567239715363352\n",
      "2000 0.0014557667490227005\n",
      "1960.540721 (s)\n",
      "(30, 30)\n",
      "----------------- 8 -----------------\n",
      "data_saving (%) 90.44444444444444\n",
      "   0 1.3180099160399166\n",
      "  50 0.08666002182825905\n",
      " 100 0.0692692822148003\n",
      " 150 0.059828228587248775\n",
      " 200 0.055523803325781385\n",
      " 250 0.05129410067594733\n",
      " 300 0.0451738373028512\n",
      " 350 0.036762041779622084\n",
      " 400 0.028252584541664228\n",
      " 450 0.01957652457343043\n",
      " 500 0.014448699912282464\n",
      " 550 0.01059046111019325\n",
      " 600 0.008230956607423498\n",
      " 650 0.006611758255753942\n",
      " 700 0.005651392779552155\n",
      " 750 0.004450566074137588\n",
      " 800 0.0038016745545814096\n",
      " 850 0.0032969647677482013\n",
      " 900 0.003267071545830007\n",
      " 950 0.0026724774268579547\n",
      "1000 0.0024300708669884813\n",
      "1050 0.0022319848873789076\n",
      "1100 0.00225693317713809\n",
      "1150 0.0019582028802381532\n",
      "1200 0.001828613654749079\n",
      "1250 0.0017045856637047173\n",
      "1300 0.001713764084780056\n",
      "1350 0.0014853380612185186\n",
      "1400 0.001390467689563244\n",
      "1450 0.0013120839220884812\n",
      "1500 0.0012423471545787957\n",
      "1550 0.00233736363765223\n",
      "1600 0.0011440164229575024\n",
      "1650 0.0010609586054636205\n",
      "1700 0.0010070325405375324\n",
      "1750 0.0009620220050707015\n",
      "1800 0.0009221047738393012\n",
      "1850 0.0008857825388657041\n",
      "1900 0.0008522656833372844\n",
      "1950 0.0008210234461186616\n",
      "2000 0.0007916476480652323\n",
      "1958.699856 (s)\n",
      "(30, 30)\n",
      "----------------- 9 -----------------\n",
      "data_saving (%) 90.44444444444444\n",
      "   0 1.591380866667213\n",
      "  50 0.135392349239832\n",
      " 100 0.11491680440128822\n",
      " 150 0.09997334192254752\n",
      " 200 0.08832263488152321\n",
      " 250 0.07763674888371264\n",
      " 300 0.06882447291465389\n",
      " 350 0.062197522655872486\n",
      " 400 0.05724759825451114\n",
      " 450 0.0533712006902982\n",
      " 500 0.05026326337087509\n",
      " 550 0.04777199845375237\n",
      " 600 0.045705156006615545\n",
      " 650 0.043845095934924916\n",
      " 700 0.04200670253084206\n",
      " 750 0.041452512904811376\n",
      " 800 0.039117531724449435\n",
      " 850 0.037449726982819516\n",
      " 900 0.03580032815150952\n",
      " 950 0.03421134567360958\n",
      "1000 0.032617255873518575\n",
      "1050 0.03135945880998446\n",
      "1100 0.029555617742954284\n",
      "1150 0.02772307921456333\n",
      "1200 0.025820192173823735\n",
      "1250 0.026300641632815376\n",
      "1300 0.022760551649491263\n",
      "1350 0.0210329869154658\n",
      "1400 0.019580625290734004\n",
      "1450 0.018176784567985212\n",
      "1500 0.017659244160987145\n",
      "1550 0.015427807945234217\n",
      "1600 0.014150009225288687\n",
      "1650 0.012634350099551234\n",
      "1700 0.011735526617412147\n",
      "1750 0.010952591410843244\n",
      "1800 0.012251741385113195\n",
      "1850 0.00982925789083872\n",
      "1900 0.009265065835387377\n",
      "1950 0.008760830606103262\n",
      "2000 0.008296526910789954\n",
      "1983.975029 (s)\n",
      "(30, 30)\n",
      "----------------- 10 -----------------\n",
      "data_saving (%) 92.55555555555556\n",
      "   0 1.8581576151494086\n",
      "  50 0.12317212049758784\n",
      " 100 0.09991672298878969\n",
      " 150 0.08438608548712377\n",
      " 200 0.07176073308503328\n",
      " 250 0.06525395655597775\n",
      " 300 0.06039307181541291\n",
      " 350 0.05598002025600539\n",
      " 400 0.051880543416723476\n",
      " 450 0.04808890372834189\n",
      " 500 0.04518874926720884\n",
      " 550 0.04218105732275257\n",
      " 600 0.03968342016233822\n",
      " 650 0.03792838072145542\n",
      " 700 0.03618153517842493\n",
      " 750 0.034403697277221215\n",
      " 800 0.03256458718309461\n",
      " 850 0.03081129534835015\n",
      " 900 0.02926707494721504\n",
      " 950 0.027895780877684073\n",
      "1000 0.026653626376548455\n",
      "1050 0.025492016594483427\n",
      "1100 0.027057341449625426\n",
      "1150 0.02349985162662964\n",
      "1200 0.022591036298429595\n",
      "1250 0.021703939784412107\n",
      "1300 0.02083706324692451\n",
      "1350 0.019992946961040224\n",
      "1400 0.01917603993561724\n",
      "1450 0.0183898590235027\n",
      "1500 0.017803014916951496\n",
      "1550 0.017126669988987826\n",
      "1600 0.016448832356708326\n",
      "1650 0.01586638338919749\n",
      "1700 0.015296324104021285\n",
      "1750 0.014736435458574015\n",
      "1800 0.014333380190293926\n",
      "1850 0.013816578118587157\n",
      "1900 0.01332479064226547\n",
      "1950 0.012877048152354685\n",
      "2000 0.012437409481473247\n",
      "1990.454044 (s)\n",
      "(30, 30)\n",
      "----------------- 11 -----------------\n",
      "data_saving (%) 90.44444444444444\n",
      "   0 1.2006590611062853\n",
      "  50 0.1398180198344641\n",
      " 100 0.11802818172686266\n",
      " 150 0.10639850333337549\n",
      " 200 0.09748467584833669\n",
      " 250 0.08946153052840589\n",
      " 300 0.08217470670582222\n",
      " 350 0.07609351511269415\n",
      " 400 0.0709140235657029\n",
      " 450 0.06632434708978806\n",
      " 500 0.0622886392660908\n",
      " 550 0.058723110600073763\n",
      " 600 0.05534123195712938\n",
      " 650 0.05196346852089237\n",
      " 700 0.04871982227042709\n",
      " 750 0.045725884826714545\n",
      " 800 0.0430072467576318\n",
      " 850 0.04052137170064388\n",
      " 900 0.03827870133614114\n",
      " 950 0.03621158963902538\n",
      "1000 0.03429589966269482\n",
      "1050 0.032447713618398835\n",
      "1100 0.03071758362497365\n",
      "1150 0.0291279665275841\n",
      "1200 0.02765306430730609\n",
      "1250 0.02642925691932555\n",
      "1300 0.025287026115910195\n",
      "1350 0.024266852368027787\n",
      "1400 0.023354428186887807\n",
      "1450 0.022504250287917152\n",
      "1500 0.023014671818670243\n",
      "1550 0.021105285135481346\n",
      "1600 0.02043361355303315\n",
      "1650 0.019771402789892197\n",
      "1700 0.019646582540297407\n",
      "1750 0.01862009534526825\n",
      "1800 0.017973929307520908\n",
      "1850 0.017379939853972876\n",
      "1900 0.01678483207314763\n",
      "1950 0.017201059794641278\n",
      "2000 0.015746126198645554\n",
      "1350.354722 (s)\n",
      "(30, 30)\n",
      "----------------- 12 -----------------\n",
      "data_saving (%) 90.44444444444444\n",
      "   0 6.915457582352449\n",
      "  50 0.20994740501161255\n",
      " 100 0.17026031346641982\n",
      " 150 0.1458452191492642\n",
      " 200 0.12933688527905585\n",
      " 250 0.11914612452948427\n",
      " 300 0.11275665873797447\n",
      " 350 0.1083287906006652\n",
      " 400 0.1049062029583941\n",
      " 450 0.10205513957668028\n",
      " 500 0.09956215366260275\n",
      " 550 0.09729875008906358\n",
      " 600 0.09517889007328673\n",
      " 650 0.09314630516119003\n",
      " 700 0.09116695987339277\n",
      " 750 0.08922270473435238\n",
      " 800 0.08730720977340163\n",
      " 850 0.08542404125868094\n",
      " 900 0.08358509122337925\n",
      " 950 0.08180752768498778\n",
      "1000 0.08010897050448548\n",
      "1050 0.07850239345052835\n",
      "1100 0.07699281193354157\n",
      "1150 0.07557681236695254\n",
      "1200 0.07424436991366398\n",
      "1250 0.07298149154929065\n",
      "1300 0.07177247338991319\n",
      "1350 0.07060135453782619\n",
      "1400 0.06945273073321978\n",
      "1450 0.0683122549789155\n",
      "1500 0.06716706874142575\n",
      "1550 0.06600625791552366\n",
      "1600 0.06482128821270074\n",
      "1650 0.06360626266330038\n",
      "1700 0.06235779058034345\n",
      "1750 0.0610743309741832\n",
      "1800 0.059755115861884034\n",
      "1850 0.05839908688332189\n",
      "1900 0.05700449398753609\n",
      "1950 0.05556971815419849\n",
      "2000 0.05409538886040444\n",
      "1256.55848 (s)\n",
      "(30, 30)\n",
      "----------------- 13 -----------------\n",
      "data_saving (%) 90.44444444444444\n",
      "   0 0.5084487237558825\n",
      "  50 0.1309787477386647\n",
      " 100 0.11154571728278363\n",
      " 150 0.10103054960500027\n",
      " 200 0.09572828006356113\n",
      " 250 0.0928577146599882\n",
      " 300 0.09066771315317199\n",
      " 350 0.08858009188629247\n",
      " 400 0.08649327988210807\n",
      " 450 0.08433652652859826\n",
      " 500 0.08195745061691574\n",
      " 550 0.07920281488453\n",
      " 600 0.07604721151940327\n",
      " 650 0.07263237260583853\n",
      " 700 0.06918771230710638\n",
      " 750 0.0658759715467164\n",
      " 800 0.06267799908786036\n",
      " 850 0.05947701260494571\n",
      " 900 0.05635972129850505\n",
      " 950 0.05369552964007385\n",
      "1000 0.051651417539717595\n",
      "1050 0.05021307906206336\n",
      "1100 0.048946697959503356\n",
      "1150 0.04790994397808587\n",
      "1200 0.047007134986646354\n",
      "1250 0.04622144138435587\n",
      "1300 0.04561176234559642\n",
      "1350 0.045000967810389036\n",
      "1400 0.04447357986260375\n",
      "1450 0.04396714080964437\n",
      "1500 0.0434707835072376\n",
      "1550 0.04302111176514298\n",
      "1600 0.04257109246420175\n",
      "1650 0.04213812676938921\n",
      "1700 0.04171462849026861\n",
      "1750 0.04130150890541115\n",
      "1800 0.040971816620861766\n",
      "1850 0.040554209385189215\n",
      "1900 0.04019361616784322\n",
      "1950 0.039830628494684495\n",
      "2000 0.03946120961828144\n",
      "1193.659196 (s)\n",
      "(30, 30)\n",
      "----------------- 14 -----------------\n",
      "data_saving (%) 90.44444444444444\n",
      "   0 0.5405065989640143\n",
      "  50 0.15097609441406296\n",
      " 100 0.1358722578970213\n",
      " 150 0.12300804902523822\n",
      " 200 0.11224889980052047\n",
      " 250 0.10316652830306228\n",
      " 300 0.09546568130851954\n",
      " 350 0.08901294201547262\n",
      " 400 0.08372050256075957\n",
      " 450 0.07945644099441293\n",
      " 500 0.0760308037004572\n",
      " 550 0.0732310313993978\n",
      " 600 0.07086202002279836\n",
      " 650 0.06876837206632154\n",
      " 700 0.06683964150052867\n",
      " 750 0.0650062570150903\n",
      " 800 0.06323147067563788\n",
      " 850 0.061502233141852006\n",
      " 900 0.05982075747748362\n",
      " 950 0.05819765308402504\n",
      "1000 0.05664675270194748\n",
      "1050 0.055181404483621896\n",
      "1100 0.053812031776539995\n",
      "1150 0.05254488999057058\n",
      "1200 0.05138193590844587\n",
      "1250 0.05032155120498974\n",
      "1300 0.049359686503319865\n",
      "1350 0.048490976375511655\n",
      "1400 0.047709539540520096\n",
      "1450 0.04700940602006562\n",
      "1500 0.046384671849340205\n",
      "1550 0.04582952342643786\n",
      "1600 0.0453382342290511\n",
      "1650 0.04490517795850708\n",
      "1700 0.04452486208579228\n",
      "1750 0.04419197058431097\n",
      "1800 0.04390140480271884\n",
      "1850 0.04364831663753852\n",
      "1900 0.043428132829505965\n",
      "1950 0.04323657172984159\n",
      "2000 0.04306965453363189\n",
      "1219.748188 (s)\n",
      "(30, 30)\n"
     ]
    }
   ],
   "source": [
    "#iterative TT decomp + retraining\n",
    "\n",
    "#reset tcPINN\n",
    "og_model = tf.keras.models.load_model(model_name)\n",
    "og_weights = og_model.get_weights()\n",
    "tcPINN.set_weights(og_weights)\n",
    "for i in range(11): #num layers + 1\n",
    "    tcPINN.layers[i].set_trainable = True\n",
    "\n",
    "print(calc_loss(tcPINN))\n",
    "\n",
    "# print('----------------- input layer -----------------')\n",
    "\n",
    "# #get specific layer of weights\n",
    "# layer = tcPINN.get_weights()[0]\n",
    "# weights = tcPINN.get_weights()\n",
    "\n",
    "# #compress layer\n",
    "# compressed_layer = decomp_recomp(layer, 0.5, [6, 5, 4], 'input layer', True)\n",
    "\n",
    "# #input compressed layer\n",
    "# weights[0] = compressed_layer\n",
    "# tcPINN.set_weights(weights)\n",
    "\n",
    "# #freeze layer\n",
    "# tcPINN.layers[0].trainable = False\n",
    "\n",
    "# #retrain\n",
    "# retrain(tcPINN, 1000)\n",
    "for layer_index in range(1, 11): #num layers + 1\n",
    "\n",
    "    print('-----------------', layer_index, '-----------------')\n",
    "\n",
    "    #get specific layer of weights\n",
    "    layer = tcPINN.get_weights()[layer_index * 2]\n",
    "    weights = tcPINN.get_weights()\n",
    "\n",
    "    #compress layer\n",
    "    compressed_layer = decomp_recomp(layer, 1, [25, 10, 10], layer_index, False)\n",
    "    #20x20 = [10, 8, 5]\n",
    "    #30x30 = [10, 10, 9]\n",
    "    #40x40 = [16, 10, 10]\n",
    "    #50x50 = [25, 10, 10]\n",
    "\n",
    "    #input compressed layer\n",
    "    weights[layer_index * 2] = compressed_layer\n",
    "    tcPINN.set_weights(weights)\n",
    "\n",
    "    #freeze layer\n",
    "    tcPINN.layers[layer_index].trainable = False\n",
    "\n",
    "    #retrain\n",
    "    retrain(tcPINN, 2000)\n",
    "\n",
    "    print(tcPINN.get_weights()[layer_index * 2].shape)\n",
    "\n",
    "#retrain(tcPINN, 4000)\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruct 14x50 perchance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterative TT decomp + retraining\n",
    "\n",
    "#reset tcPINN\n",
    "og_model = tf.keras.models.load_model(model_name)\n",
    "og_weights = og_model.get_weights()\n",
    "tcPINN.set_weights(og_weights)\n",
    "for i in range(11): #num layers + 1\n",
    "    tcPINN.layers[i].set_trainable = True\n",
    "\n",
    "print(calc_loss(tcPINN))\n",
    "\n",
    "# print('----------------- input layer -----------------')\n",
    "\n",
    "# #get specific layer of weights\n",
    "# layer = tcPINN.get_weights()[0]\n",
    "# weights = tcPINN.get_weights()\n",
    "\n",
    "# #compress layer\n",
    "# compressed_layer = decomp_recomp(layer, 0.5, [6, 5, 4], 'input layer', True)\n",
    "\n",
    "# #input compressed layer\n",
    "# weights[0] = compressed_layer\n",
    "# tcPINN.set_weights(weights)\n",
    "\n",
    "# #freeze layer\n",
    "# tcPINN.layers[0].trainable = False\n",
    "\n",
    "# #retrain\n",
    "# retrain(tcPINN, 1000)\n",
    "\n",
    "for layer_index in range(1, 12): #num layers + 1\n",
    "\n",
    "    print('-----------------', layer_index, '-----------------')\n",
    "\n",
    "    #get specific layer of weights\n",
    "    layer = tcPINN.get_weights()[layer_index * 2]\n",
    "    weights = tcPINN.get_weights()\n",
    "\n",
    "    #compress layer \n",
    "    #20x20 = [10, 8, 5]\n",
    "    #30x30 = [10, 10, 9]\n",
    "    #40x40 = 16 10 10\n",
    "    #50x50 = 25 10 10\n",
    "\n",
    "    #input compressed layer\n",
    "    weights[layer_index * 2] = compressed_layer\n",
    "    tcPINN.set_weights(weights)\n",
    "\n",
    "    #freeze layer\n",
    "    tcPINN.layers[layer_index].trainable = False\n",
    "\n",
    "    #retrain\n",
    "    retrain(tcPINN, 2000)\n",
    "\n",
    "    print(tcPINN.get_weights()[layer_index * 2].shape)\n",
    "\n",
    "#retrain(tcPINN, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "tcPINN.save('tc_b_14x30.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- input layer -----------------\n",
      "data_saving (%) 19.999999999999996\n"
     ]
    }
   ],
   "source": [
    "#compress input layer\n",
    "print('----------------- input layer -----------------')\n",
    "\n",
    "#get specific layer of weights\n",
    "layer = tcPINN.get_weights()[0]\n",
    "weights = tcPINN.get_weights()\n",
    "\n",
    "#compress layer\n",
    "compressed_layer = decomp_recomp(layer, 0.5, [6, 5, 4], 'input layer', False)\n",
    "\n",
    "# #input compressed layer\n",
    "# weights[0] = compressed_layer\n",
    "# tcPINN.set_weights(weights)\n",
    "\n",
    "# #freeze layer\n",
    "# tcPINN.layers[0].trainable = False\n",
    "\n",
    "# #retrain\n",
    "# retrain(tcPINN, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load compressed input layer\n",
    "\n",
    "compressed_input_layer = np.load('input_layer_0.73_0.0069.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_330 (Dense)           (None, 40)                120       \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_334 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_335 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_336 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_337 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_338 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_339 (Dense)           (None, 1)                 41        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,281\n",
      "Trainable params: 13,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "----------------- 1 -----------------\n",
      "(40, 40)\n",
      "data_saving (%) 88.625\n",
      "----------------- 2 -----------------\n",
      "(40, 40)\n",
      "data_saving (%) 94.0\n",
      "----------------- 3 -----------------\n",
      "(40, 40)\n",
      "data_saving (%) 94.0\n",
      "----------------- 4 -----------------\n",
      "(40, 40)\n",
      "data_saving (%) 94.0\n",
      "----------------- 5 -----------------\n",
      "(40, 40)\n",
      "data_saving (%) 94.0\n",
      "----------------- 6 -----------------\n",
      "(40, 40)\n",
      "data_saving (%) 94.0\n",
      "----------------- 7 -----------------\n",
      "(40, 40)\n",
      "data_saving (%) 94.0\n",
      "----------------- 8 -----------------\n",
      "(40, 40)\n",
      "data_saving (%) 88.625\n"
     ]
    }
   ],
   "source": [
    "tcPINN = tf.keras.models.load_model('b_8x40.h5')\n",
    "tcPINN.summary()\n",
    "\n",
    "for layer_index in range(1, 9):\n",
    "\n",
    "    print('-----------------', layer_index, '-----------------')\n",
    "\n",
    "    #get specific layer of weights\n",
    "    layer = tcPINN.get_weights()[layer_index * 2]\n",
    "    weights = tcPINN.get_weights()\n",
    "    print(layer.shape)\n",
    "    decomp_recomp(layer, 1, [16, 10, 10], layer_index, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#save original weights\n",
    "tcPINN = tf.keras.models.load_model(\"burgers.h5\")\n",
    "\n",
    "for layer_index in range(0, 10):\n",
    "\n",
    "    #get specific layer of weights\n",
    "    layer = tcPINN.get_weights()[layer_index * 2 + 1]\n",
    "    np.save(f'{layer_index}.npy', layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "0.0006366909955450453\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_284 (Dense)           (None, 30)                90        \n",
      "                                                                 \n",
      " dense_285 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_286 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_287 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_288 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_289 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_290 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_291 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_292 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_293 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_294 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_295 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_296 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_297 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_298 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_299 (Dense)           (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,141\n",
      "Trainable params: 13,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('b_14x30.h5')\n",
    "\n",
    "print(calc_loss(model))\n",
    "model.summary()\n",
    "#retrain(model, 500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
