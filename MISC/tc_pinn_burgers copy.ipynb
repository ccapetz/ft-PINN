{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor-Compressed PINN for Solving Burgers Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backend/Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pcdcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy.stats import qmc\n",
    "import tensorlearn as tl\n",
    "import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##nn basics\n",
    "\n",
    "def read_network(network_path):\n",
    "\n",
    "    saved_model = tf.keras.models.load_model(network_path)\n",
    "\n",
    "    return saved_model\n",
    "\n",
    "\n",
    "\n",
    "def layer_param(nn_model, layer_name):\n",
    "\n",
    "    return nn_model.get_layer(layer_name).weights\n",
    "\n",
    "\n",
    "\n",
    "def get_dense_layer_weights(param):\n",
    "    return param[0].numpy()\n",
    "\n",
    "def get_dense_layer_bias(param):\n",
    "    return param[1].numpy()\n",
    "\n",
    "def set_dense_layer_param_list(weights,bias):\n",
    "    return [weights,bias]\n",
    "\n",
    "\n",
    "    \n",
    "def freez_layer(nn_model,index, param_layer):\n",
    "    nn_model.layers[index].set_weights(param_layer)\n",
    "    nn_model.layers[index].trainable=False\n",
    "    return nn_model\n",
    "\n",
    "\n",
    "def net_retrain(nn_model, ds_train, ds_test, epochs, output_path):\n",
    "\n",
    "\n",
    "    checkpoint_path=output_path\n",
    "    cp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 save_weights_only=False,\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "    nn_model.fit(\n",
    "                ds_train,\n",
    "                epochs=epochs,\n",
    "                validation_data=ds_test,\n",
    "                callbacks=[cp_callback]\n",
    "            )                \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    nn_model.save(output_path)\n",
    "    return nn_model\n",
    "\n",
    "\n",
    "def get_layer_index_by_name(model, layer_name):\n",
    "    for index, layer in enumerate(model.layers):\n",
    "        if layer.name == layer_name:\n",
    "            return index\n",
    "        \n",
    "\n",
    "def inference(nn_model, ds_test):\n",
    "    return nn_model.evaluate(ds_test)\n",
    "\n",
    "\n",
    "\n",
    "def mnist_data_load(batch_size=128):\n",
    "        tfds.disable_progress_bar()\n",
    "        #tf.enable_v2_behavior()\n",
    "        \n",
    "        (ds_train, ds_test), ds_info = tfds.load(\n",
    "            'fashion_mnist',\n",
    "            split=['train', 'test'],\n",
    "            shuffle_files=True,\n",
    "            as_supervised=True,\n",
    "            with_info=True,\n",
    "        )\n",
    "        \n",
    "        def normalize_img(image, label):\n",
    "          \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "          return tf.cast(image, tf.float32) / 255., label\n",
    "        \n",
    "        ds_train = ds_train.map(\n",
    "            normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        ds_train = ds_train.cache()\n",
    "        ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "        ds_train = ds_train.batch(batch_size)\n",
    "        ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "        ds_test = ds_test.map(\n",
    "            normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        ds_test = ds_test.batch(batch_size)\n",
    "        ds_test = ds_test.cache()\n",
    "        ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        return ds_train, ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_29 (InputLayer)       [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_376 (Dense)           (None, 20)                60        \n",
      "                                                                 \n",
      " dense_377 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " dense_378 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " dense_379 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " dense_380 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " dense_381 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " dense_382 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " dense_383 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " dense_384 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " dense_385 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " dense_386 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " dense_387 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " dense_388 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " dense_389 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " dense_390 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " dense_391 (Dense)           (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,961\n",
      "Trainable params: 5,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "#tcPINN = tf.keras.models.load_model(\"b_14x50.h5\")\n",
    "model_name = 'b_14x20.h5'\n",
    "tcPINN = tf.keras.models.load_model(model_name)\n",
    "tcPINN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available.\n"
     ]
    }
   ],
   "source": [
    "#FIX THIS - GPU setup\n",
    "#pip install tensorflow-gpu\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) == 0:\n",
    "    print(\"No GPU available.\")\n",
    "else:\n",
    "    print(\"GPU(s) available:\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decomposing and recomposing a layer of weights\n",
    "def decomp_recomp(weights, epsilon, shape, layer, save_layer):\n",
    "\n",
    "    og_shape = np.array(weights.shape)\n",
    "    #print(type(og_shape))\n",
    "    np_weights = np.array(weights)\n",
    "    #print(np_weights.shape)\n",
    "    #print(type(np_weights))\n",
    "\n",
    "    weights_3d = np.reshape(np_weights, shape).astype(np.float64) #shape search???\n",
    "    #20x20 = 10 8 5\n",
    "    #40x40 = 16 10 10\n",
    "    #60x60 = 16 15 15\n",
    "\n",
    "    #print(type(weights_3d))\n",
    "\n",
    "    #decompose/recompose\n",
    "    tt_weights = tl.auto_rank_tt(weights_3d, epsilon) #error of 0.5 - 1, tweak w shape search?\n",
    "    recomp_weights = tl.tt_to_tensor(tt_weights)\n",
    "\n",
    "    #data saving\n",
    "    compression_ratio = tl.tt_compression_ratio(tt_weights)\n",
    "    data_saving = 1 - (1/compression_ratio)\n",
    "    print(\"data_saving (%)\", data_saving*100)\n",
    "\n",
    "    #save compressed layer\n",
    "    if(save_layer):\n",
    "        tt_weights_npy = np.array(tt_weights, dtype=object)\n",
    "        np.save(f'{layer}.npy', tt_weights_npy)\n",
    "\n",
    "    return np.reshape(recomp_weights, og_shape) #og shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate loss\n",
    "\n",
    "### generating data\n",
    "\n",
    "# number of boundary and initial data points\n",
    "# value `Nd` in the reference paper:\n",
    "# Nd = number_of_ic_points + number_of_bc1_points + number_of_bc1_points \n",
    "number_of_ic_points = 50\n",
    "number_of_bc1_points = 25\n",
    "number_of_bc2_points = 25\n",
    "\n",
    "# Latin Hypercube Sampling (LHS) engine ; to sample random points in domain,\n",
    "# boundary and initial boundary\n",
    "engine = qmc.LatinHypercube(d=1)\n",
    "\n",
    "# temporal data points\n",
    "t_d = engine.random(n=number_of_bc1_points + number_of_bc2_points)\n",
    "temp = np.zeros([number_of_ic_points, 1]) # for IC ; t = 0\n",
    "t_d = np.append(temp, t_d, axis=0)\n",
    "# spatial data points\n",
    "x_d = engine.random(n=number_of_ic_points)\n",
    "x_d = 2 * (x_d - 0.5)\n",
    "temp1 = -1 * np.ones([number_of_bc1_points, 1]) # for BC1 ; x = -1\n",
    "temp2 = +1 * np.ones([number_of_bc2_points, 1]) # for BC2 ; x = +1\n",
    "x_d = np.append(x_d, temp1, axis=0)\n",
    "x_d = np.append(x_d, temp2, axis=0)\n",
    "\n",
    "# output values for data points (boundary and initial)\n",
    "y_d = np.zeros(x_d.shape)\n",
    "\n",
    "# for initial condition: IC = -sin(pi*x)\n",
    "y_d[ : number_of_ic_points] = -np.sin(np.pi * x_d[:number_of_ic_points])\n",
    "\n",
    "# all boundary conditions are set to zero\n",
    "y_d[number_of_ic_points : number_of_bc1_points + number_of_ic_points] = 0\n",
    "y_d[number_of_bc1_points + number_of_ic_points : number_of_bc1_points + number_of_ic_points + number_of_bc2_points] = 0\n",
    "\n",
    "# number of collocation points\n",
    "Nc = 10000\n",
    "\n",
    "# LHS for collocation points\n",
    "engine = qmc.LatinHypercube(d=2)\n",
    "data = engine.random(n=Nc)\n",
    "# set x values between -1. and +1.\n",
    "data[:, 1] = 2*(data[:, 1]-0.5)\n",
    "\n",
    "# change names\n",
    "t_c = np.expand_dims(data[:, 0], axis=1)\n",
    "x_c = np.expand_dims(data[:, 1], axis=1)\n",
    "\n",
    "# MSE loss function\n",
    "# IMPORTANT: this loss function is used for data points\n",
    "@tf.function\n",
    "def mse(y, y_):\n",
    "    return tf.reduce_mean(tf.square(y-y_))\n",
    "\n",
    "def calc_loss(model):\n",
    "\n",
    "    # u(t, x) just makes working with model easier and the whole code looks more\n",
    "    # like its mathematical backend\n",
    "    @tf.function\n",
    "    def u(t, x, model):\n",
    "        # model input shape is (2,) and `u` recieves 2 arguments with shape (1,)\n",
    "        # to be able to feed those 2 args (t, x) to the model, a shape (2,) matrix\n",
    "        # is build by simply concatenation of (t, x)\n",
    "        u = model(tf.concat([t, x], axis=1)) # note the axis ; `column`\n",
    "        return u\n",
    "    \n",
    "    # the physics informed loss function\n",
    "    # IMPORTANT: this loss function is used for collocation points\n",
    "    @tf.function\n",
    "    def f(t, x, model):\n",
    "        u0 = u(t, x, model)\n",
    "        u_t = tf.gradients(u0, t)[0]\n",
    "        u_x = tf.gradients(u0, x)[0]\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        F = u_t + u0*u_x - (0.01/np.pi)*u_xx\n",
    "        return tf.reduce_mean(tf.square(F))\n",
    "    \n",
    "    # model output/prediction\n",
    "    y_ = u(t_d, x_d, model)\n",
    "    # physics-informed loss for collocation points\n",
    "    L1 = f(t_c, x_c, model)\n",
    "    # MSE loss for data points\n",
    "    L2 = mse(y_d, y_)\n",
    "    loss = L1 + L2\n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain model\n",
    "\n",
    "def retrain(model, epochs):\n",
    "\n",
    "    #loss funciton definitions\n",
    "    # u(t, x) just makes working with model easier and the whole code looks more\n",
    "    # like its mathematical backend\n",
    "    @tf.function\n",
    "    def u(t, x, model):\n",
    "        # model input shape is (2,) and `u` recieves 2 arguments with shape (1,)\n",
    "        # to be able to feed those 2 args (t, x) to the model, a shape (2,) matrix\n",
    "        # is build by simply concatenation of (t, x)\n",
    "        u = model(tf.concat([t, x], axis=1)) # note the axis ; `column`\n",
    "        return u\n",
    "    \n",
    "    # the physics informed loss function\n",
    "    # IMPORTANT: this loss function is used for collocation points\n",
    "    @tf.function\n",
    "    def f(t, x, model):\n",
    "        u0 = u(t, x, model)\n",
    "        u_t = tf.gradients(u0, t)[0]\n",
    "        u_x = tf.gradients(u0, x)[0]\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        F = u_t + u0*u_x - (0.01/np.pi)*u_xx\n",
    "        return tf.reduce_mean(tf.square(F))\n",
    "\n",
    "    loss_list = []\n",
    "\n",
    "    # L-BFGS optimizer was used in the reference paper\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    start = time.time()\n",
    "\n",
    "    # training loop\n",
    "    # IMPORTANT: a while-based training loop is more beneficial\n",
    "    # updates the model while loss > 0.006\n",
    "    for epoch in range(epochs + 1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # model output/prediction\n",
    "            y_ = u(t_d, x_d, model)\n",
    "            # physics-informed loss for collocation points\n",
    "            L1 = f(t_c, x_c, model)\n",
    "            # MSE loss for data points\n",
    "            L2 = mse(y_d, y_)\n",
    "            loss = L1 + L2\n",
    "        # compute gradients\n",
    "        g = tape.gradient(loss, model.trainable_weights)\n",
    "        loss_list.append(loss)\n",
    "        # log every 10 epochs\n",
    "        if (not epoch%50) or (epoch == epochs):\n",
    "            print(f\"{epoch:4} {loss.numpy()}\")\n",
    "        # apply gradients\n",
    "        opt.apply_gradients(zip(g, model.trainable_weights))\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"{end - start:.10} (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You called `set_weights(weights)` on layer \"model_28\" with a weight list of length 20, but the layer was expecting 32 weights. Provided weights: [array([[-0.21136272, -0.43254922, -0.00763503,  0...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m og_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m\"\u001b[39m\u001b[39mburgers.h5\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m#loss = 0.00591\u001b[39;00m\n\u001b[0;32m      3\u001b[0m og_weights \u001b[39m=\u001b[39m og_model\u001b[39m.\u001b[39mget_weights()\n\u001b[1;32m----> 4\u001b[0m tcPINN\u001b[39m.\u001b[39;49mset_weights(og_weights)\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m11\u001b[39m):\n\u001b[0;32m      6\u001b[0m     tcPINN\u001b[39m.\u001b[39mlayers[i]\u001b[39m.\u001b[39mset_trainable \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pcdcm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\base_layer.py:1802\u001b[0m, in \u001b[0;36mLayer.set_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1799\u001b[0m         expected_num_weights \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1801\u001b[0m \u001b[39mif\u001b[39;00m expected_num_weights \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(weights):\n\u001b[1;32m-> 1802\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1803\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mYou called `set_weights(weights)` on layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1804\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwith a weight list of length \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, but the layer was \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1805\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mexpecting \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m weights. Provided weights: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1806\u001b[0m         \u001b[39m%\u001b[39m (\n\u001b[0;32m   1807\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[0;32m   1808\u001b[0m             \u001b[39mlen\u001b[39m(weights),\n\u001b[0;32m   1809\u001b[0m             expected_num_weights,\n\u001b[0;32m   1810\u001b[0m             \u001b[39mstr\u001b[39m(weights)[:\u001b[39m50\u001b[39m],\n\u001b[0;32m   1811\u001b[0m         )\n\u001b[0;32m   1812\u001b[0m     )\n\u001b[0;32m   1814\u001b[0m weight_index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m   1815\u001b[0m weight_value_tuples \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: You called `set_weights(weights)` on layer \"model_28\" with a weight list of length 20, but the layer was expecting 32 weights. Provided weights: [array([[-0.21136272, -0.43254922, -0.00763503,  0..."
     ]
    }
   ],
   "source": [
    "#reset tcPINN\n",
    "og_model = tf.keras.models.load_model(\"burgers.h5\") #loss = 0.00591\n",
    "og_weights = og_model.get_weights()\n",
    "tcPINN.set_weights(og_weights)\n",
    "for i in range(11):\n",
    "    tcPINN.layers[i].set_trainable = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual TT Decomp and Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "0.002072769113209222\n",
      "----------------- 1 -----------------\n",
      "data_saving (%) 91.0\n",
      "   0 0.889498992281876\n",
      "  50 0.10818005014863721\n",
      " 100 0.07129425656774295\n",
      " 150 0.03681271376458474\n",
      " 200 0.013459866647122107\n",
      " 250 0.006402367264166113\n",
      " 300 0.005872811028724447\n",
      " 350 0.00380862126768688\n",
      " 400 0.0030787342957615217\n",
      " 450 0.0028476169798709195\n",
      " 500 0.002783277286120653\n",
      " 550 0.0022028991906198636\n",
      " 600 0.002588404403919672\n",
      " 650 0.0018620361862146536\n",
      " 700 0.02586771182196075\n",
      " 750 0.0021450115296230057\n",
      " 800 0.001655248326315583\n",
      " 850 0.0015376246777182062\n",
      " 900 0.0014605635953099686\n",
      " 950 0.0013925330774942582\n",
      "1000 0.0013298459840470436\n",
      "1050 0.0012712389362249488\n",
      "1100 0.0012159480180302577\n",
      "1150 0.03560029733943057\n",
      "1200 0.002907062021056523\n",
      "1250 0.0013357254829354085\n",
      "1300 0.0011852456145121431\n",
      "1350 0.0011036997650924088\n",
      "1400 0.0010503463582579677\n",
      "1450 0.001006845368704829\n",
      "1500 0.000967610901220008\n",
      "1550 0.0009309982354503523\n",
      "1600 0.0008963221783513714\n",
      "1650 0.0008632562505418778\n",
      "1700 0.03135752162084883\n",
      "1750 0.0028742126795489355\n",
      "1800 0.0011439974632188978\n",
      "1850 0.0009082045113572561\n",
      "1900 0.0008549846040032739\n",
      "1950 0.0008258156111649729\n",
      "2000 0.00080186015269717\n",
      "1525.935707 (s)\n",
      "(20, 20)\n",
      "----------------- 2 -----------------\n",
      "data_saving (%) 91.0\n",
      "   0 0.7115906376535802\n",
      "  50 0.19393855838709273\n",
      " 100 0.11777489059974085\n",
      " 150 0.09902745130303098\n",
      " 200 0.08716519597617851\n",
      " 250 0.08008379270478294\n",
      " 300 0.07446225634593243\n",
      " 350 0.07031674108474312\n",
      " 400 0.06662105358976608\n",
      " 450 0.06298648091286504\n",
      " 500 0.059371855037289124\n",
      " 550 0.056068048757625014\n",
      " 600 0.05312477656572523\n",
      " 650 0.050407887631072554\n",
      " 700 0.04789052237574867\n",
      " 750 0.04456188130737705\n",
      " 800 0.039880084772424\n",
      " 850 0.03637813129666069\n",
      " 900 0.027785505296172207\n",
      " 950 0.023087408284257066\n",
      "1000 0.015024824086069656\n",
      "1050 0.010117443120959989\n",
      "1100 0.008432980472060161\n",
      "1150 0.004894120119690162\n",
      "1200 0.003943107232086732\n",
      "1250 0.003204191155648078\n",
      "1300 0.0026922759881368823\n",
      "1350 0.002318480602788503\n",
      "1400 0.004657896244123694\n",
      "1450 0.00191824308929523\n",
      "1500 0.0016970446638562564\n",
      "1550 0.0015595375014299552\n",
      "1600 0.0014429490418237725\n",
      "1650 0.0013412968731293248\n",
      "1700 0.008002920028079175\n",
      "1750 0.004251446773235049\n",
      "1800 0.0015614000579822595\n",
      "1850 0.0012751859763777843\n",
      "1900 0.001180895774689606\n",
      "1950 0.0011185752210730957\n",
      "2000 0.0010670886328674886\n",
      "1468.967499 (s)\n",
      "(20, 20)\n",
      "----------------- 3 -----------------\n",
      "data_saving (%) 79.25\n",
      "   0 1.4056475491084945\n",
      "  50 0.0288399940922084\n",
      " 100 0.0184583311917861\n",
      " 150 0.013483435509413198\n",
      " 200 0.009946496013963104\n",
      " 250 0.007468054613643848\n",
      " 300 0.006103078864177674\n",
      " 350 0.005244026183857078\n",
      " 400 0.004624716028043064\n",
      " 450 0.00403888352550318\n",
      " 500 0.0035017259943050487\n",
      " 550 0.003181266573348147\n",
      " 600 0.002929067371061074\n",
      " 650 0.0027151711405493063\n",
      " 700 0.002531384900855296\n",
      " 750 0.0023733711833592783\n",
      " 800 0.0022377801827779646\n",
      " 850 0.002121550532483052\n",
      " 900 0.0020217777969849075\n",
      " 950 0.0019357642134464788\n",
      "1000 0.0018610989000938374\n",
      "1050 0.0017957060793398808\n",
      "1100 0.0017378508867531462\n",
      "1150 0.00168611578770532\n",
      "1200 0.0016393623236678487\n",
      "1250 0.0015966878481918313\n",
      "1300 0.0015573827487388467\n",
      "1350 0.0015208911833384591\n",
      "1400 0.0014867768049682557\n",
      "1450 0.0014546938149146483\n",
      "1500 0.0014243627575321713\n",
      "1550 0.0013955494518027446\n",
      "1600 0.0013680434218675713\n",
      "1650 0.0013416251137795777\n",
      "1700 0.00131597463284693\n",
      "1750 0.0012901757058633914\n",
      "1800 0.0012584012724258793\n",
      "1850 0.001218643386045716\n",
      "1900 0.001192570749437685\n",
      "1950 0.0043829107850545165\n",
      "2000 0.0012200440553201\n",
      "1459.157959 (s)\n",
      "(20, 20)\n",
      "----------------- 4 -----------------\n",
      "data_saving (%) 91.0\n",
      "   0 2.013707232581027\n",
      "  50 0.12317776666196441\n",
      " 100 0.112794968575143\n",
      " 150 0.1059027249754453\n",
      " 200 0.1007833662109009\n",
      " 250 0.0965906248229955\n",
      " 300 0.09258658569156103\n",
      " 350 0.0893253701346951\n",
      " 400 0.08681239928656825\n",
      " 450 0.08434144556971236\n",
      " 500 0.07343445642675589\n",
      " 550 0.0533069268399234\n",
      " 600 0.04527991167509172\n",
      " 650 0.03791753507947884\n",
      " 700 0.025295626657272745\n",
      " 750 0.013774501553977745\n",
      " 800 0.008601242143715158\n",
      " 850 0.006392997611973435\n",
      " 900 0.005134539559660494\n",
      " 950 0.0042490963584132955\n",
      "1000 0.00355586333174598\n",
      "1050 0.0030077370154980194\n",
      "1100 0.0025755719601136947\n",
      "1150 0.0022058686983384254\n",
      "1200 0.0019030455791763995\n",
      "1250 0.0016675233481225757\n",
      "1300 0.0014803438520368181\n",
      "1350 0.0022971037438179027\n",
      "1400 0.001248310596621395\n",
      "1450 0.0011477202842425241\n",
      "1500 0.0010636553516318488\n",
      "1550 0.0009915767610010433\n",
      "1600 0.00092892070503687\n",
      "1650 0.000879311276379729\n",
      "1700 0.0008473393858010399\n",
      "1750 0.0007937208755905184\n",
      "1800 0.0007544352734013363\n",
      "1850 0.002952513444158535\n",
      "1900 0.0006955047577806852\n",
      "1950 0.0006678238955795078\n",
      "2000 0.0007708841515249581\n",
      "1482.732873 (s)\n",
      "(20, 20)\n",
      "----------------- 5 -----------------\n",
      "data_saving (%) 91.0\n",
      "   0 0.3302004141516912\n",
      "  50 0.12924632539317296\n",
      " 100 0.11179242449891238\n",
      " 150 0.09864812766728304\n",
      " 200 0.08381430051824948\n",
      " 250 0.06920463199083299\n",
      " 300 0.05899520090494062\n",
      " 350 0.0532172155637735\n",
      " 400 0.051119415770983084\n",
      " 450 0.049354735506835404\n",
      " 500 0.04828960437134051\n",
      " 550 0.04723636488134343\n",
      " 600 0.04607177786626607\n",
      " 650 0.044821498857413\n",
      " 700 0.04100775358961486\n",
      " 750 0.03631918281680634\n",
      " 800 0.02965842688790747\n",
      " 850 0.025022084843922335\n",
      " 900 0.018559660582510323\n",
      " 950 0.015607769017010649\n",
      "1000 0.014979165690358325\n",
      "1050 0.015852888788463082\n",
      "1100 0.011387966830934071\n",
      "1150 0.010151849824531343\n",
      "1200 0.009252091431668118\n",
      "1250 0.011757540076275455\n",
      "1300 0.007717529756401828\n",
      "1350 0.007025528032360413\n",
      "1400 0.014897999631819873\n",
      "1450 0.010871081707779893\n",
      "1500 0.005594484935652329\n",
      "1550 0.004981627326614179\n",
      "1600 0.0047112952898484\n",
      "1650 0.004494763256811955\n",
      "1700 0.0042986321284877935\n",
      "1750 0.004115514726450736\n",
      "1800 0.00394260994192488\n",
      "1850 0.0037784358844246014\n",
      "1900 0.00362203837612257\n",
      "1950 0.003472716976671293\n",
      "2000 0.0033299152965967547\n",
      "1483.328442 (s)\n",
      "(20, 20)\n",
      "----------------- 6 -----------------\n",
      "data_saving (%) 91.0\n",
      "   0 10.623281271432347\n",
      "  50 0.24881802584646762\n",
      " 100 0.23152226173857246\n",
      " 150 0.2222079676245588\n",
      " 200 0.21162017667347882\n",
      " 250 0.20051046920298074\n",
      " 300 0.19155752550191152\n",
      " 350 0.1842495738081232\n",
      " 400 0.17520748673151046\n",
      " 450 0.1628444129775283\n",
      " 500 0.14944077778495343\n",
      " 550 0.13959670338153674\n",
      " 600 0.13053709995905735\n",
      " 650 0.12352172859398877\n",
      " 700 0.11887909849378825\n",
      " 750 0.11379074275184828\n",
      " 800 0.10788081942910975\n",
      " 850 0.10244103551032055\n",
      " 900 0.09831704499848462\n",
      " 950 0.09451519042525856\n",
      "1000 0.09075557794784392\n",
      "1050 0.08714273003805462\n",
      "1100 0.08372165295332862\n",
      "1150 0.08038197859781329\n",
      "1200 0.07682202740117987\n",
      "1250 0.07340751513385169\n",
      "1300 0.07024708632922619\n",
      "1350 0.06752826711080032\n",
      "1400 0.06529228184797219\n",
      "1450 0.06344003497835779\n",
      "1500 0.061825187673678436\n",
      "1550 0.060320130673946176\n",
      "1600 0.05882892339702097\n",
      "1650 0.057278699176070286\n",
      "1700 0.055622375572484575\n",
      "1750 0.053858500906999715\n",
      "1800 0.0520125518070812\n",
      "1850 0.050054933532720176\n",
      "1900 0.04785616749849607\n",
      "1950 0.04523527366018468\n",
      "2000 0.042065684630937517\n",
      "1466.569646 (s)\n",
      "(20, 20)\n",
      "----------------- 7 -----------------\n",
      "data_saving (%) 91.0\n",
      "   0 0.47648663627203425\n",
      "  50 0.20262638590924364\n",
      " 100 0.1880458146543157\n",
      " 150 0.15350203915268684\n",
      " 200 0.13948403326545905\n",
      " 250 0.13157518140831026\n",
      " 300 0.12259304035847893\n",
      " 350 0.11540531019436748\n",
      " 400 0.1084454164712825\n",
      " 450 0.09769365550403503\n",
      " 500 0.0861030650979403\n",
      " 550 0.07973038697649049\n",
      " 600 0.0739523826821033\n",
      " 650 0.06705284830245468\n",
      " 700 0.06342257013911796\n",
      " 750 0.060596254238779\n",
      " 800 0.058256031417538434\n",
      " 850 0.055848886612663115\n",
      " 900 0.05338190268737207\n",
      " 950 0.05101151280638675\n",
      "1000 0.048854018424831336\n",
      "1050 0.04714287702096808\n",
      "1100 0.046128685695544444\n",
      "1150 0.043876973770594685\n",
      "1200 0.041807615297766505\n",
      "1250 0.03908568913002726\n",
      "1300 0.03612738227587331\n",
      "1350 0.03239704896791183\n",
      "1400 0.029719082547621237\n",
      "1450 0.02611885421320785\n",
      "1500 0.02495601114934099\n",
      "1550 0.023521993603527205\n",
      "1600 0.019057890693705337\n",
      "1650 0.016552704754481028\n",
      "1700 0.014343110359178294\n",
      "1750 0.0755319480728528\n",
      "1800 0.01225932809976203\n",
      "1850 0.010535413761433677\n",
      "1900 0.009707507347814281\n",
      "1950 0.008980795870946825\n",
      "2000 0.008314225794479832\n",
      "1448.210683 (s)\n",
      "(20, 20)\n",
      "----------------- 8 -----------------\n",
      "data_saving (%) 91.0\n",
      "   0 4.981835077668968\n",
      "  50 0.30540391915893617\n",
      " 100 0.22735345001936488\n",
      " 150 0.1841806204590024\n",
      " 200 0.15108099892128096\n",
      " 250 0.1319813528056519\n",
      " 300 0.12219815423670001\n",
      " 350 0.11463364236475733\n",
      " 400 0.10702706159463048\n",
      " 450 0.10002927746659603\n",
      " 500 0.0940178102541328\n",
      " 550 0.09066629185822199\n",
      " 600 0.08878305660439284\n",
      " 650 0.08739947428281736\n",
      " 700 0.08622309066333571\n",
      " 750 0.0851659843016495\n",
      " 800 0.08418746523443646\n",
      " 850 0.08326159988043758\n",
      " 900 0.0823744738653728\n",
      " 950 0.08152542099945362\n",
      "1000 0.08072227436967246\n",
      "1050 0.07996982508715375\n",
      "1100 0.07926209857879793\n",
      "1150 0.07858460805716534\n",
      "1200 0.07792068638042246\n",
      "1250 0.077255702319539\n",
      "1300 0.0765784467242779\n",
      "1350 0.07588064451544532\n",
      "1400 0.07515510628326755\n",
      "1450 0.07439387954212628\n",
      "1500 0.07358732630818177\n",
      "1550 0.07272403208345224\n",
      "1600 0.07179250667621079\n",
      "1650 0.0707887996928119\n",
      "1700 0.06973202632880261\n",
      "1750 0.06866591403283538\n",
      "1800 0.06764976163078096\n",
      "1850 0.066761562772129\n",
      "1900 0.06601755931807614\n",
      "1950 0.06537808871552571\n",
      "2000 0.0648059461911062\n",
      "1415.255121 (s)\n",
      "(20, 20)\n",
      "----------------- 9 -----------------\n",
      "data_saving (%) 91.0\n",
      "   0 0.37980732775644593\n",
      "  50 0.11143974615372165\n",
      " 100 0.0947432803620619\n",
      " 150 0.0882860886050929\n",
      " 200 0.08368676584849925\n",
      " 250 0.08009655551532763\n",
      " 300 0.07705783904022914\n",
      " 350 0.07408461391454557\n",
      " 400 0.07099247003843023\n",
      " 450 0.06785880599794583\n",
      " 500 0.06524180818576582\n",
      " 550 0.0634249720029412\n",
      " 600 0.06206156894786913\n",
      " 650 0.06085609601622463\n",
      " 700 0.059713056872118614\n",
      " 750 0.058572728734225345\n",
      " 800 0.05734511887661149\n",
      " 850 0.055916252591862003\n",
      " 900 0.05417600825610054\n",
      " 950 0.052144492294219566\n",
      "1000 0.050049786517977854\n",
      "1050 0.04786002265134788\n",
      "1100 0.044801238228305756\n",
      "1150 0.0410574461185512\n",
      "1200 0.03614055423626462\n",
      "1250 0.03259269194935511\n",
      "1300 0.02874448171530916\n",
      "1350 0.02595543329947888\n",
      "1400 0.02329670027031147\n",
      "1450 0.02085577176634124\n",
      "1500 0.019256056433486088\n",
      "1550 0.016726209075648445\n",
      "1600 0.014805462770946923\n",
      "1650 0.014047688331356115\n",
      "1700 0.013766741778524876\n",
      "1750 0.010912051703497537\n",
      "1800 0.010018960408885296\n",
      "1850 0.01163243150638914\n",
      "1900 0.008824127741493968\n",
      "1950 0.008409198884998801\n",
      "2000 0.007900114306144453\n",
      "1421.026695 (s)\n",
      "(20, 20)\n",
      "----------------- 10 -----------------\n",
      "data_saving (%) 91.0\n",
      "   0 1.0687435959954759\n",
      "  50 0.20358514452615462\n",
      " 100 0.16518452500155412\n",
      " 150 0.12953895644230737\n",
      " 200 0.10985238408194536\n",
      " 250 0.09856468502898033\n",
      " 300 0.09384436837209538\n",
      " 350 0.09048845960100695\n",
      " 400 0.08787619211800557\n",
      " 450 0.08577152566558835\n",
      " 500 0.0840259745820447\n",
      " 550 0.08255829360075344\n",
      " 600 0.08132618441125924\n",
      " 650 0.08029370525822338\n",
      " 700 0.07941396672127335\n",
      " 750 0.0786392486057613\n",
      " 800 0.07793195374782245\n",
      " 850 0.07726629933212753\n",
      " 900 0.07662586143196612\n",
      " 950 0.07600058639706997\n",
      "1000 0.07538400373300093\n",
      "1050 0.07477077081089295\n",
      "1100 0.07415459246587779\n",
      "1150 0.07352704452682896\n",
      "1200 0.07287798210869531\n",
      "1250 0.07219698892656451\n",
      "1300 0.0714743866489538\n",
      "1350 0.07070100668324489\n",
      "1400 0.06986687148226667\n",
      "1450 0.06895891406874166\n",
      "1500 0.06795759818892946\n",
      "1550 0.06683342161794073\n",
      "1600 0.06554784791342429\n",
      "1650 0.06406872572208228\n",
      "1700 0.06241373448518828\n",
      "1750 0.06072375965671306\n",
      "1800 0.05929206178513996\n",
      "1850 0.058316832491807996\n",
      "1900 0.05765649738536896\n",
      "1950 0.05710875536073842\n",
      "2000 0.056585338479881855\n",
      "1404.155457 (s)\n",
      "(20, 20)\n",
      "----------------- 11 -----------------\n",
      "data_saving (%) 91.0\n",
      "   0 0.9560184699388392\n",
      "  50 0.16863630986879213\n",
      " 100 0.14597922397581306\n",
      " 150 0.13640827288599677\n",
      " 200 0.12793287496396066\n",
      " 250 0.1195587519126626\n",
      " 300 0.11249688478610662\n",
      " 350 0.1056821136958654\n",
      " 400 0.09919733499132123\n",
      " 450 0.09392393410501373\n",
      " 500 0.09031665513451345\n",
      " 550 0.08808169920444145\n",
      " 600 0.08671011706340863\n",
      " 650 0.08582032038960143\n",
      " 700 0.08518134545212672\n",
      " 750 0.08466443723700999\n",
      " 800 0.08420217216886382\n",
      " 850 0.08376119879500485\n",
      " 900 0.0833254473475785\n",
      " 950 0.08288655217509718\n",
      "1000 0.08243890424978524\n",
      "1050 0.08197744667418329\n",
      "1100 0.08149693989032877\n",
      "1150 0.08099192169591313\n",
      "1200 0.08045695573112545\n",
      "1250 0.07988700111105329\n",
      "1300 0.0792778730004978\n",
      "1350 0.07862683129202196\n",
      "1400 0.07793334082746364\n",
      "1450 0.07719997260829661\n",
      "1500 0.07643322893955827\n",
      "1550 0.07564377955687678\n",
      "1600 0.07484534478868064\n",
      "1650 0.07405167437273885\n",
      "1700 0.07327219545537954\n",
      "1750 0.07250853705900853\n",
      "1800 0.07175450593641083\n",
      "1850 0.0709999142271378\n",
      "1900 0.07023577827627159\n",
      "1950 0.06945791390014738\n",
      "2000 0.06866784713146104\n",
      "1366.716506 (s)\n",
      "(20, 20)\n",
      "----------------- 12 -----------------\n",
      "data_saving (%) 91.0\n",
      "   0 0.880000748575\n",
      "  50 0.13699834954684312\n",
      " 100 0.1202312934097815\n",
      " 150 0.11325701140247474\n",
      " 200 0.10825519828597141\n",
      " 250 0.10452287251610282\n",
      " 300 0.10155712860240881\n",
      " 350 0.09904901156514234\n",
      " 400 0.09683044582725045\n",
      " 450 0.09478847165363274\n",
      " 500 0.09286534198530424\n",
      " 550 0.09106341655378432\n",
      " 600 0.08942825005386516\n",
      " 650 0.08801203607387945\n",
      " 700 0.08683757395548185\n",
      " 750 0.0858905127387322\n",
      " 800 0.08513019898673621\n",
      " 850 0.08450495021745025\n",
      " 900 0.08396760229918916\n",
      " 950 0.08348380037670418\n",
      "1000 0.0830315449636833\n",
      "1050 0.08259689647621418\n",
      "1100 0.08216996817660663\n",
      "1150 0.0817424570474938\n",
      "1200 0.08130641089195682\n",
      "1250 0.0808536435690912\n",
      "1300 0.08037538074196413\n",
      "1350 0.07986191473837324\n",
      "1400 0.07930217495925065\n",
      "1450 0.07868322463540564\n",
      "1500 0.07798987470529123\n",
      "1550 0.07720503838559635\n",
      "1600 0.07631247433954617\n",
      "1650 0.07530550019086577\n",
      "1700 0.07420622628192436\n",
      "1750 0.07308895221183667\n",
      "1800 0.07206732830833293\n",
      "1850 0.07121460053960274\n",
      "1900 0.07051110042908129\n",
      "1950 0.06989492012365427\n",
      "2000 0.06931959794514592\n",
      "1349.452735 (s)\n",
      "(20, 20)\n",
      "----------------- 13 -----------------\n",
      "data_saving (%) 91.0\n",
      "   0 1.1732352311798147\n",
      "  50 0.21887664260422537\n",
      " 100 0.1798466380325686\n",
      " 150 0.15330071241511925\n",
      " 200 0.13474754087519755\n",
      " 250 0.12404053449916731\n",
      " 300 0.11896899241587802\n",
      " 350 0.11626801250314603\n",
      " 400 0.11418281369351078\n",
      " 450 0.11226977602043851\n",
      " 500 0.11048399661727154\n",
      " 550 0.10883336215489853\n",
      " 600 0.10731664159423952\n",
      " 650 0.10591794290073453\n",
      " 700 0.10461046411349066\n",
      " 750 0.10336283983608831\n",
      " 800 0.10214544680465176\n",
      " 850 0.10093498678334079\n",
      " 900 0.09971691686813013\n",
      " 950 0.09848607379461874\n",
      "1000 0.0972460472086487\n",
      "1050 0.09600778304921873\n",
      "1100 0.09478711301143855\n",
      "1150 0.09360082112219519\n",
      "1200 0.09246563302132123\n",
      "1250 0.09141125815075554\n",
      "1300 0.09048708685881358\n",
      "1350 0.08971738007388003\n",
      "1400 0.08908393738879118\n",
      "1450 0.08856149820530254\n",
      "1500 0.08813196690043554\n",
      "1550 0.08777883475862355\n",
      "1600 0.0874842877904105\n",
      "1650 0.08723104510947263\n",
      "1700 0.08700457355031103\n",
      "1750 0.0867938152393059\n",
      "1800 0.08659076600575039\n",
      "1850 0.08638966432190227\n",
      "1900 0.08618622701892056\n",
      "1950 0.08597706227165919\n",
      "2000 0.08575925433764799\n",
      "1337.41818 (s)\n",
      "(20, 20)\n",
      "----------------- 14 -----------------\n",
      "data_saving (%) 91.0\n",
      "   0 8.999846951527124\n",
      "  50 1.1821894187412696\n",
      " 100 0.42277609190006066\n",
      " 150 0.2868771993316364\n",
      " 200 0.2497451774267163\n",
      " 250 0.23246327503374697\n",
      " 300 0.21974763631053038\n",
      " 350 0.20904856643471526\n",
      " 400 0.20005793951626308\n",
      " 450 0.19264897376070128\n",
      " 500 0.18660056099206962\n",
      " 550 0.18163128526233066\n",
      " 600 0.17745863180103577\n",
      " 650 0.17383696673174132\n",
      " 700 0.17057266794986964\n",
      " 750 0.16752374988849641\n",
      " 800 0.16459171169067568\n",
      " 850 0.16171114538500486\n",
      " 900 0.15884019976840874\n",
      " 950 0.15595319106648636\n",
      "1000 0.1530355925446122\n",
      "1050 0.15008112699476486\n",
      "1100 0.14709048686816426\n",
      "1150 0.14407112898296245\n",
      "1200 0.14103752811240045\n",
      "1250 0.13801121140010753\n",
      "1300 0.13501991014458395\n",
      "1350 0.13209538646332866\n",
      "1400 0.12926998862665282\n",
      "1450 0.12657262414772394\n",
      "1500 0.12402526014118316\n",
      "1550 0.12164094160758142\n",
      "1600 0.11942369336881031\n",
      "1650 0.11736995012832066\n",
      "1700 0.11547076491575792\n",
      "1750 0.11371408171932713\n",
      "1800 0.11208663409018267\n",
      "1850 0.11057531555730502\n",
      "1900 0.10916804688113049\n",
      "1950 0.10785423961770581\n",
      "2000 0.10662496704185674\n",
      "1312.958817 (s)\n",
      "(20, 20)\n"
     ]
    }
   ],
   "source": [
    "#iterative TT decomp + retraining\n",
    "\n",
    "#reset tcPINN\n",
    "og_model = tf.keras.models.load_model(model_name)\n",
    "og_weights = og_model.get_weights()\n",
    "tcPINN.set_weights(og_weights)\n",
    "for i in range(15): #num layers + 1\n",
    "    tcPINN.layers[i].set_trainable = True\n",
    "\n",
    "print(calc_loss(tcPINN))\n",
    "\n",
    "# print('----------------- input layer -----------------')\n",
    "\n",
    "# #get specific layer of weights\n",
    "# layer = tcPINN.get_weights()[0]\n",
    "# weights = tcPINN.get_weights()\n",
    "\n",
    "# #compress layer\n",
    "# compressed_layer = decomp_recomp(layer, 0.5, [6, 5, 4], 'input layer', True)\n",
    "\n",
    "# #input compressed layer\n",
    "# weights[0] = compressed_layer\n",
    "# tcPINN.set_weights(weights)\n",
    "\n",
    "# #freeze layer\n",
    "# tcPINN.layers[0].trainable = False\n",
    "\n",
    "# #retrain\n",
    "# retrain(tcPINN, 1000)\n",
    "for layer_index in range(1, 15): #num layers + 1\n",
    "\n",
    "    print('-----------------', layer_index, '-----------------')\n",
    "\n",
    "    #get specific layer of weights\n",
    "    layer = tcPINN.get_weights()[layer_index * 2]\n",
    "    weights = tcPINN.get_weights()\n",
    "\n",
    "    #compress layer\n",
    "    compressed_layer = decomp_recomp(layer, 1, [10, 8, 5], layer_index, False)\n",
    "    #20x20 = [10, 8, 5]\n",
    "    #30x30 = [10, 10, 9]\n",
    "    #40x40 = [16, 10, 10]\n",
    "    #50x50 = 25 10 10\n",
    "\n",
    "    #input compressed layer\n",
    "    weights[layer_index * 2] = compressed_layer\n",
    "    tcPINN.set_weights(weights)\n",
    "\n",
    "    #freeze layer\n",
    "    tcPINN.layers[layer_index].trainable = False\n",
    "\n",
    "    #retrain\n",
    "    retrain(tcPINN, 2000)\n",
    "\n",
    "    print(tcPINN.get_weights()[layer_index * 2].shape)\n",
    "\n",
    "#retrain(tcPINN, 4000)\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruct 14x50 perchance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterative TT decomp + retraining\n",
    "\n",
    "#reset tcPINN\n",
    "og_model = tf.keras.models.load_model(model_name)\n",
    "og_weights = og_model.get_weights()\n",
    "tcPINN.set_weights(og_weights)\n",
    "for i in range(11): #num layers + 1\n",
    "    tcPINN.layers[i].set_trainable = True\n",
    "\n",
    "print(calc_loss(tcPINN))\n",
    "\n",
    "# print('----------------- input layer -----------------')\n",
    "\n",
    "# #get specific layer of weights\n",
    "# layer = tcPINN.get_weights()[0]\n",
    "# weights = tcPINN.get_weights()\n",
    "\n",
    "# #compress layer\n",
    "# compressed_layer = decomp_recomp(layer, 0.5, [6, 5, 4], 'input layer', True)\n",
    "\n",
    "# #input compressed layer\n",
    "# weights[0] = compressed_layer\n",
    "# tcPINN.set_weights(weights)\n",
    "\n",
    "# #freeze layer\n",
    "# tcPINN.layers[0].trainable = False\n",
    "\n",
    "# #retrain\n",
    "# retrain(tcPINN, 1000)\n",
    "\n",
    "for layer_index in range(1, 12): #num layers + 1\n",
    "\n",
    "    print('-----------------', layer_index, '-----------------')\n",
    "\n",
    "    #get specific layer of weights\n",
    "    layer = tcPINN.get_weights()[layer_index * 2]\n",
    "    weights = tcPINN.get_weights()\n",
    "\n",
    "    #compress layer \n",
    "    #20x20 = [10, 8, 5]\n",
    "    #30x30 = [10, 10, 9]\n",
    "    #40x40 = 16 10 10\n",
    "    #50x50 = 25 10 10\n",
    "\n",
    "    #input compressed layer\n",
    "    weights[layer_index * 2] = compressed_layer\n",
    "    tcPINN.set_weights(weights)\n",
    "\n",
    "    #freeze layer\n",
    "    tcPINN.layers[layer_index].trainable = False\n",
    "\n",
    "    #retrain\n",
    "    retrain(tcPINN, 2000)\n",
    "\n",
    "    print(tcPINN.get_weights()[layer_index * 2].shape)\n",
    "\n",
    "#retrain(tcPINN, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "tcPINN.save('tc_b_14x20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- input layer -----------------\n",
      "data_saving (%) 19.999999999999996\n"
     ]
    }
   ],
   "source": [
    "#compress input layer\n",
    "print('----------------- input layer -----------------')\n",
    "\n",
    "#get specific layer of weights\n",
    "layer = tcPINN.get_weights()[0]\n",
    "weights = tcPINN.get_weights()\n",
    "\n",
    "#compress layer\n",
    "compressed_layer = decomp_recomp(layer, 0.5, [6, 5, 4], 'input layer', False)\n",
    "\n",
    "# #input compressed layer\n",
    "# weights[0] = compressed_layer\n",
    "# tcPINN.set_weights(weights)\n",
    "\n",
    "# #freeze layer\n",
    "# tcPINN.layers[0].trainable = False\n",
    "\n",
    "# #retrain\n",
    "# retrain(tcPINN, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load compressed input layer\n",
    "\n",
    "compressed_input_layer = np.load('input_layer_0.73_0.0069.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_330 (Dense)           (None, 40)                120       \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_334 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_335 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_336 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_337 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_338 (Dense)           (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_339 (Dense)           (None, 1)                 41        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,281\n",
      "Trainable params: 13,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "----------------- 1 -----------------\n",
      "(40, 40)\n",
      "data_saving (%) 88.625\n",
      "----------------- 2 -----------------\n",
      "(40, 40)\n",
      "data_saving (%) 94.0\n",
      "----------------- 3 -----------------\n",
      "(40, 40)\n",
      "data_saving (%) 94.0\n",
      "----------------- 4 -----------------\n",
      "(40, 40)\n",
      "data_saving (%) 94.0\n",
      "----------------- 5 -----------------\n",
      "(40, 40)\n",
      "data_saving (%) 94.0\n",
      "----------------- 6 -----------------\n",
      "(40, 40)\n",
      "data_saving (%) 94.0\n",
      "----------------- 7 -----------------\n",
      "(40, 40)\n",
      "data_saving (%) 94.0\n",
      "----------------- 8 -----------------\n",
      "(40, 40)\n",
      "data_saving (%) 88.625\n"
     ]
    }
   ],
   "source": [
    "tcPINN = tf.keras.models.load_model('b_8x40.h5')\n",
    "tcPINN.summary()\n",
    "\n",
    "for layer_index in range(1, 9):\n",
    "\n",
    "    print('-----------------', layer_index, '-----------------')\n",
    "\n",
    "    #get specific layer of weights\n",
    "    layer = tcPINN.get_weights()[layer_index * 2]\n",
    "    weights = tcPINN.get_weights()\n",
    "    print(layer.shape)\n",
    "    decomp_recomp(layer, 1, [16, 10, 10], layer_index, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#save original weights\n",
    "tcPINN = tf.keras.models.load_model(\"burgers.h5\")\n",
    "\n",
    "for layer_index in range(0, 10):\n",
    "\n",
    "    #get specific layer of weights\n",
    "    layer = tcPINN.get_weights()[layer_index * 2 + 1]\n",
    "    np.save(f'{layer_index}.npy', layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "0.0006366909955450453\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_284 (Dense)           (None, 30)                90        \n",
      "                                                                 \n",
      " dense_285 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_286 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_287 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_288 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_289 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_290 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_291 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_292 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_293 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_294 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_295 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_296 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_297 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_298 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_299 (Dense)           (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,141\n",
      "Trainable params: 13,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('b_14x30.h5')\n",
    "\n",
    "print(calc_loss(model))\n",
    "model.summary()\n",
    "#retrain(model, 500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
